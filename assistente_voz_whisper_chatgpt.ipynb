{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOOaJhEOfQgRzpzc4GK+LO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardofoltran/assistente-voz-whisper-chatgpt/blob/main/assistente_voz_whisper_chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2IT72ww7Du0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Passo 1 - DefiniÃ§Ã£o de Idioma\n"
      ],
      "metadata": {
        "id": "ajUwdwNerkxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "language = 'pt'  # pt = portuguÃªs | en = inglÃªs | es = espanhol"
      ],
      "metadata": {
        "id": "drOAPndVpOBh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 2 â€“ GravaÃ§Ã£o de Ãudio no Google Colab ðŸŽ¤\n",
        "\n",
        "ðŸŽ§ ObservaÃ§Ã£o sobre a gravaÃ§Ã£o de Ã¡udio\n",
        "\n",
        "Durante o desenvolvimento deste projeto, um Ã¡udio de teste pode jÃ¡ estar salvo no notebook.\n",
        "\n",
        "Para utilizar **sua prÃ³pria voz**, execute novamente a cÃ©lula de gravaÃ§Ã£o de Ã¡udio abaixo.  \n",
        "Ao executar a cÃ©lula, o navegador solicitarÃ¡ permissÃ£o de acesso ao microfone.\n",
        "\n",
        "âž¡ï¸ Sempre que quiser gravar um novo Ã¡udio, basta **executar novamente a cÃ©lula de gravaÃ§Ã£o**.\n"
      ],
      "metadata": {
        "id": "SDj8cVCxpeOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ReferÃªncia: https://gist.github.com/korakot/c21c3476c024ad6d56d5f48b0bca92be\n",
        "\n",
        "from IPython.display import Audio, display, Javascript\n",
        "from google.colab import output\n",
        "from base64 import b64decode\n",
        "\n",
        "# CÃ³digo JavaScript para gravar Ã¡udio do usuÃ¡rio usando a \"MediaStream Recording API\"\n",
        "RECORD = \"\"\"\n",
        "const sleep  = time => new Promise(resolve => setTimeout(resolve, time))\n",
        "const b2text = blob => new Promise(resolve => {\n",
        "  const reader = new FileReader()\n",
        "  reader.onloadend = e => resolve(e.srcElement.result)\n",
        "  reader.readAsDataURL(blob)\n",
        "})\n",
        "var record = time => new Promise(async resolve => {\n",
        "  stream = await navigator.mediaDevices.getUserMedia({ audio: true })\n",
        "  recorder = new MediaRecorder(stream)\n",
        "  chunks = []\n",
        "  recorder.ondataavailable = e => chunks.push(e.data)\n",
        "  recorder.start()\n",
        "  await sleep(time)\n",
        "  recorder.onstop = async ()=>{\n",
        "    blob = new Blob(chunks)\n",
        "    text = await b2text(blob)\n",
        "    resolve(text)\n",
        "  }\n",
        "  recorder.stop()\n",
        "})\n",
        "\"\"\"\n",
        "\n",
        "def record_audio(seconds=5):\n",
        "    display(Javascript(RECORD))\n",
        "    print(\"ðŸŽ§ Gravando Ã¡udio...\")\n",
        "\n",
        "    audio_data = output.eval_js(f'record({seconds * 1000})')\n",
        "    audio_bytes = b64decode(audio_data.split(',')[1])\n",
        "    with open('/content/audio_usuario.wav', 'wb') as f:\n",
        "        f.write(audio_bytes)\n",
        "\n",
        "    return '/content/audio_usuario.wav'\n",
        "\n",
        "# Call the function and store the result before displaying\n",
        "audio_file_path = record_audio(5) # Records for 5 seconds\n",
        "display(Audio(audio_file_path))"
      ],
      "metadata": {
        "id": "eGNXxIeZppkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo 3 â€“ Reconhecimento de Fala com Whisper ðŸ§ \n",
        "\n"
      ],
      "metadata": {
        "id": "H16eAvXUqs-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e7E02I-PpyBB",
        "outputId": "892eab66-4e19-45f8-ae52-388098e84ab9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1KEeBR5rBPU",
        "outputId": "72e51a43-0c45-4024-899a-339202302289"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 461M/461M [00:01<00:00, 252MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe(audio_file_path, fp16=False, language=language)\n",
        "transcription = result[\"text\"]\n",
        "\n",
        "print(\"ðŸ“ TranscriÃ§Ã£o:\")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voqfI3LmrJzI",
        "outputId": "1e2bb588-5651-4a6f-8d17-f2cda19147df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“ TranscriÃ§Ã£o:\n",
            " Um, dois, trÃªs, testando, opa, opa!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ” Passo 4 â€“ IntegraÃ§Ã£o com ChatGPT ðŸ’¬\n",
        "\n",
        "Nesta etapa, o projeto se conecta Ã  **API da OpenAI (ChatGPT)** para gerar uma resposta inteligente a partir do texto transcrito pelo Whisper.\n",
        "\n",
        "âš ï¸ **Importante â€“ SeguranÃ§a da API Key**\n",
        "\n",
        "Por motivos de seguranÃ§a, **nenhuma API Key Ã© fornecida neste projeto**.\n",
        "\n",
        "Para executar corretamente este passo, **vocÃª deve utilizar a sua prÃ³pria API Key da OpenAI**.\n",
        "\n",
        "### Como configurar:\n",
        "\n",
        "1. Acesse o site da OpenAI e gere sua API Key:\n",
        "   - https://platform.openai.com/account/api-keys\n",
        "\n",
        "2. No cÃ³digo abaixo, substitua o valor:\n",
        "   ```python\n",
        "   'SUA_API_KEY_AQUI'\n"
      ],
      "metadata": {
        "id": "iJycTAhOsECN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "id": "tP3i-dxDsFK_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = 'SUA_API_KEY_AQUI'\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ],
      "metadata": {
        "id": "VkW2gV4csQ0H"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client (API key is picked up from environment variables)\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"VocÃª Ã© um assistente de voz inteligente.\"},\n",
        "        {\"role\": \"user\", \"content\": transcription}\n",
        "    ]\n",
        ")\n",
        "\n",
        "chatgpt_response = response.choices[0].message.content\n",
        "\n",
        "print(\"ðŸ¤– Resposta do ChatGPT:\")\n",
        "print(chatgpt_response)"
      ],
      "metadata": {
        "id": "kSrKbmDFs58Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Passo 5 â€“ Converter Resposta em Ãudio (Text-to-Speech) ðŸ”Š"
      ],
      "metadata": {
        "id": "GQQJHfdtuLUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS -q"
      ],
      "metadata": {
        "id": "LTs1qxGcuMdm"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "\n",
        "tts = gTTS(\n",
        "    text=chatgpt_response,\n",
        "    lang=language,\n",
        "    slow=False\n",
        ")\n",
        "\n",
        "response_audio_path = \"/content/resposta_assistente.wav\"\n",
        "tts.save(response_audio_path)"
      ],
      "metadata": {
        "id": "fRi_WEYkuOOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Audio(response_audio_path, autoplay=True))"
      ],
      "metadata": {
        "id": "QxkJDgXtuQ16"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}